"""
Artifact Entity Classes
Dataclasses to store outputs from each pipeline component
"""

from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime


# ============== DATA INGESTION ARTIFACT ==============
@dataclass
class DataIngestionArtifact:
    """Artifact generated by Data Ingestion component"""
    
    # File Paths
    raw_file_path: str
    train_file_path: str
    test_file_path: str
    
    # Data Statistics
    total_records: int
    train_records: int
    test_records: int
    
    # Target Distribution
    fraud_count: int
    non_fraud_count: int
    fraud_percentage: float
    
    # Metadata
    ingestion_timestamp: str = field(
        default_factory=lambda: datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    )
    source_type: str = "csv"
    is_ingested: bool = True
    message: str = "Data Ingestion Completed Successfully"


# ============== DATA VALIDATION ARTIFACT ==============
@dataclass
class DataValidationArtifact:
    """Artifact generated by Data Validation component"""
    
    # Validation Status
    is_validated: bool
    validation_status: str  # "PASSED" or "FAILED"
    
    # Report Path
    validation_report_path: str
    drift_report_path: Optional[str] = None
    
    # Validation Details
    missing_columns: List[str] = field(default_factory=list)
    extra_columns: List[str] = field(default_factory=list)
    dtype_mismatch_columns: Dict[str, str] = field(default_factory=dict)
    
    # Statistics
    missing_value_columns: Dict[str, float] = field(default_factory=dict)
    duplicate_rows: int = 0
    
    # Metadata
    validation_timestamp: str = field(
        default_factory=lambda: datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    )
    message: str = ""


# ============== DATA TRANSFORMATION ARTIFACT ==============
@dataclass
class DataTransformationArtifact:
    """Artifact generated by Data Transformation component"""
    
    # Transformed Data Paths
    transformed_train_path: str
    transformed_test_path: str
    
    # Preprocessor Paths
    preprocessor_path: str
    encoder_path: Optional[str] = None
    
    # Feature Information
    feature_names: List[str] = field(default_factory=list)
    numerical_features: List[str] = field(default_factory=list)
    categorical_features: List[str] = field(default_factory=list)
    
    # Shape Information
    train_shape: tuple = (0, 0)
    test_shape: tuple = (0, 0)
    
    # Imbalance Handling
    imbalance_method: str = "none"
    original_train_size: int = 0
    resampled_train_size: int = 0
    
    # Metadata
    transformation_timestamp: str = field(
        default_factory=lambda: datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    )
    is_transformed: bool = True
    message: str = "Data Transformation Completed Successfully"


# ============== MODEL TRAINER ARTIFACT ==============
@dataclass
class ModelTrainerArtifact:
    """Artifact generated by Model Trainer component"""
    
    # Model Path
    model_path: str
    
    # Best Model Info
    best_model_name: str
    best_model_params: Dict[str, Any] = field(default_factory=dict)
    
    # Training Metrics
    train_accuracy: float = 0.0
    train_precision: float = 0.0
    train_recall: float = 0.0
    train_f1_score: float = 0.0
    train_roc_auc: float = 0.0
    
    # Validation Metrics (Cross-validation)
    cv_scores: List[float] = field(default_factory=list)
    cv_mean_score: float = 0.0
    cv_std_score: float = 0.0
    
    # Training Report
    training_report_path: str = ""
    
    # Metadata
    training_timestamp: str = field(
        default_factory=lambda: datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    )
    training_duration_seconds: float = 0.0
    is_trained: bool = True
    message: str = "Model Training Completed Successfully"


# ============== MODEL EVALUATION ARTIFACT ==============
@dataclass
class ModelEvaluationArtifact:
    """Artifact generated by Model Evaluation component"""
    
    # Evaluation Metrics
    accuracy: float = 0.0
    precision: float = 0.0
    recall: float = 0.0
    f1_score: float = 0.0
    roc_auc: float = 0.0
    pr_auc: float = 0.0
    
    # Confusion Matrix Values
    true_positives: int = 0
    true_negatives: int = 0
    false_positives: int = 0
    false_negatives: int = 0
    
    # Business Metrics (BFSI Specific)
    fraud_detection_rate: float = 0.0
    false_alarm_rate: float = 0.0
    
    # Model Acceptance
    is_model_accepted: bool = False
    acceptance_criteria: Dict[str, bool] = field(default_factory=dict)
    
    # Report Paths
    evaluation_report_path: str = ""
    confusion_matrix_path: str = ""
    roc_curve_path: str = ""
    pr_curve_path: str = ""
    
    # Metadata
    evaluation_timestamp: str = field(
        default_factory=lambda: datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    )
    message: str = ""


# ============== MODEL PUSHER ARTIFACT ==============
@dataclass
class ModelPusherArtifact:
    """Artifact generated by Model Pusher component"""
    
    # Production Model Paths
    production_model_path: str
    production_preprocessor_path: str
    
    # Model Registry
    model_version: str
    model_registry_path: str
    
    # Deployment Info
    is_pushed: bool = False
    pushed_to: str = "local"  # local, s3, mlflow, azure
    
    # Metadata
    push_timestamp: str = field(
        default_factory=lambda: datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    )
    message: str = ""


# ============== FEATURE ENGINEERING ARTIFACT ==============
@dataclass
class FeatureEngineeringArtifact:
    """Artifact generated by Feature Engineering component"""
    
    # Output Paths
    train_featured_path: str
    test_featured_path: str
    report_path: str
    
    # Feature Information
    original_features: List[str] = field(default_factory=list)
    engineered_features: List[str] = field(default_factory=list)
    final_features: List[str] = field(default_factory=list)
    dropped_features: List[str] = field(default_factory=list)
    
    # Feature Counts
    original_feature_count: int = 0
    engineered_feature_count: int = 0
    final_feature_count: int = 0
    
    # Shape Information
    train_shape: tuple = (0, 0)
    test_shape: tuple = (0, 0)
    
    # Metadata
    feature_engineering_timestamp: str = field(
        default_factory=lambda: datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    )
    is_completed: bool = True
    message: str = "Feature Engineering Completed Successfully"


# ============== DATA TRANSFORMATION ARTIFACT ==============
@dataclass
class DataTransformationArtifact:
    """Artifact generated by Data Transformation component"""
    
    # Transformed Data Paths
    train_transformed_path: str
    test_transformed_path: str
    train_target_path: str
    test_target_path: str
    
    # Preprocessor Path
    preprocessor_path: str
    feature_names_path: str
    report_path: str
    
    # Feature Information
    original_features: List[str] = field(default_factory=list)
    selected_features: List[str] = field(default_factory=list)
    dropped_features: List[str] = field(default_factory=list)
    
    # Shape Information
    original_train_shape: tuple = (0, 0)
    original_test_shape: tuple = (0, 0)
    transformed_train_shape: tuple = (0, 0)
    transformed_test_shape: tuple = (0, 0)
    
    # Imbalance Handling
    imbalance_method: str = "none"
    original_class_distribution: Dict = field(default_factory=dict)
    resampled_class_distribution: Dict = field(default_factory=dict)
    
    # Scaling Info
    scaling_method: str = "standard"
    
    # Metadata
    transformation_timestamp: str = field(
        default_factory=lambda: datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    )
    is_transformed: bool = True
    message: str = "Data Transformation Completed Successfully"


# ============== MODEL TRAINER ARTIFACT ==============
@dataclass
class ModelTrainerArtifact:
    """Artifact generated by Model Trainer component"""
    
    # Model Path
    model_path: str
    training_report_path: str
    model_comparison_path: str
    
    # Best Model Information
    best_model_name: str = ""
    best_model_params: Dict[str, Any] = field(default_factory=dict)
    
    # Training Metrics (on training set)
    train_accuracy: float = 0.0
    train_precision: float = 0.0
    train_recall: float = 0.0
    train_f1_score: float = 0.0
    train_roc_auc: float = 0.0
    
    # Cross-Validation Metrics
    cv_recall_mean: float = 0.0
    cv_recall_std: float = 0.0
    cv_precision_mean: float = 0.0
    cv_precision_std: float = 0.0
    cv_f1_mean: float = 0.0
    cv_f1_std: float = 0.0
    cv_roc_auc_mean: float = 0.0
    cv_roc_auc_std: float = 0.0
    
    # Model Comparison
    models_trained: List[str] = field(default_factory=list)
    model_scores: Dict[str, Dict] = field(default_factory=dict)
    
    # Training Info
    training_duration_seconds: float = 0.0
    hyperparameter_tuning_enabled: bool = False
    
    # Metadata
    training_timestamp: str = field(
        default_factory=lambda: datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    )
    is_trained: bool = True
    message: str = "Model Training Completed Successfully"

# ============== MODEL EVALUATION ARTIFACT ==============
@dataclass
class ModelEvaluationArtifact:
    """Artifact generated by Model Evaluation component"""
    
    # Report Paths
    evaluation_report_path: str
    business_metrics_path: str
    
    # Visualization Paths
    confusion_matrix_path: str
    roc_curve_path: str
    pr_curve_path: str
    threshold_analysis_path: str
    feature_importance_path: str
    
    # Classification Metrics
    accuracy: float = 0.0
    precision: float = 0.0
    recall: float = 0.0
    f1_score: float = 0.0
    roc_auc: float = 0.0
    pr_auc: float = 0.0
    
    # Confusion Matrix Values
    true_positives: int = 0
    true_negatives: int = 0
    false_positives: int = 0
    false_negatives: int = 0
    
    # Threshold Information
    default_threshold: float = 0.5
    optimal_threshold: float = 0.5
    threshold_optimization_metric: str = "f1"
    
    # Business Metrics
    fraud_detection_rate: float = 0.0
    false_alarm_rate: float = 0.0
    total_fraud_amount_caught: float = 0.0
    total_fraud_amount_missed: float = 0.0
    investigation_cost: float = 0.0
    net_savings: float = 0.0
    
    # Model Acceptance
    is_model_accepted: bool = False
    acceptance_criteria_results: Dict[str, bool] = field(default_factory=dict)
    
    # Feature Importance
    top_features: List[Tuple[str, float]] = field(default_factory=list)
    
    # Metadata
    evaluation_timestamp: str = field(
        default_factory=lambda: datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    )
    message: str = ""

# ============== MODEL PUSHER ARTIFACT ==============
@dataclass
class ModelPusherArtifact:
    """Artifact generated by Model Pusher component"""
    
    # Version Information
    model_version: str = ""
    previous_version: Optional[str] = None
    
    # Registry Paths
    registry_model_path: str = ""
    registry_preprocessor_path: str = ""
    registry_metadata_path: str = ""
    
    # Production Paths
    production_model_path: str = ""
    production_preprocessor_path: str = ""
    
    # Status
    is_model_registered: bool = False
    is_model_promoted: bool = False
    promotion_reason: str = ""
    
    # Comparison with Previous Version
    is_improvement: bool = False
    improvement_metrics: Dict[str, float] = field(default_factory=dict)
    
    # Model Metrics (for quick reference)
    recall: float = 0.0
    precision: float = 0.0
    f1_score: float = 0.0
    roc_auc: float = 0.0
    
    # Metadata
    push_timestamp: str = field(
        default_factory=lambda: datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    )
    message: str = ""


# ============== EXAMPLE USAGE ==============
if __name__ == "__main__":
    # Test artifacts
    ingestion_artifact = DataIngestionArtifact(
        raw_file_path="artifacts/data_ingestion/raw/transactions.csv",
        train_file_path="artifacts/data_ingestion/processed/train.csv",
        test_file_path="artifacts/data_ingestion/processed/test.csv",
        total_records=100000,
        train_records=80000,
        test_records=20000,
        fraud_count=1500,
        non_fraud_count=98500,
        fraud_percentage=1.5
    )
    
    print(f"Train Path: {ingestion_artifact.train_file_path}")
    print(f"Fraud %: {ingestion_artifact.fraud_percentage}")
    print(f"Timestamp: {ingestion_artifact.ingestion_timestamp}")